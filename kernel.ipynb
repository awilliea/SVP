{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "56f3c3499260fe04c9d0c6535f59ea3320b8c987"
      },
      "cell_type": "markdown",
      "source": "Please go through Giba's post and kernel  to underrstand what this leak is all about\nhttps://www.kaggle.com/titericz/the-property-by-giba (kernel)\nhttps://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post)\n\nAlso, go through this Jiazhen's kernel which finds more columns to exploit leak\nhttps://www.kaggle.com/johnfarrell/giba-s-property-extended-result\n\nI just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field.\n\n**Let the competition begin! :D**"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom scipy.stats import mode, skew, kurtosis, entropy\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport dask.dataframe as dd\nfrom dask.multiprocessing import get\n\nfrom tqdm import tqdm, tqdm_notebook\ntqdm.pandas(tqdm_notebook)\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc37a766646b5993cef0bc87ad6882728dd20cb2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\ntransact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\ny = np.log1p(train[\"target\"]).values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6dcfc4df1340c38bfeac43fd4d19ba2763b3b916"
      },
      "cell_type": "markdown",
      "source": "We take time series columns from [here](https://www.kaggle.com/johnfarrell/giba-s-property-extended-result)"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', \n        'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5',\n        '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867',\n        'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7',\n        '1931ccfdd', '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n        '6619d81fc', '1db387535'] +\n\nauth_cols1 = ['9b490abb3', 'b10f15193', '05f54f417', 'a7ac690a8', 'ed6c300c2', 'd0803e3a1', 'b1bb8eac3',\n 'bd1c19973', 'a34f8d443', '84ec1e3db', '24018f832', '82e01a220', '4c2064b00', 'ba42e41fa', '0397f7c9b',\n '22d7ad48d', '9abffd22c', 'dbfa2b77f', '2c6c62b54', '9fa38def3', 'ecb354edf',\n '9c3154ae6',\n '2f26d70f4',\n '53102b93f',\n 'a36b95f78',\n '1fa0f78d0',\n '19915a6d3',\n 'c944a48b5',\n '482b04cba',\n '2ce77a58f',\n '86558e595',\n '20305585c',\n 'c3f400e36',\n 'f8ccfa064',\n 'dd771cb8e',\n '9aa27017e',\n 'cd7f0affd',\n '236cc1ff5',\n 'a3fc511cd']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d61c75092518f50a879e9e3d5883ab752f73912b"
      },
      "cell_type": "code",
      "source": "from multiprocessing import Pool\nCPU_CORES = 1\ndef _get_leak(df, cols, lag=0):\n    \"\"\" To get leak value, we do following:\n       1. Get string of all values after removing first two time steps\n       2. For all rows we shift the row by two steps and again make a string\n       3. Just find rows where string from 2 matches string from 1\n       4. Get 1st time step of row in 3 (Currently, there is additional condition to only fetch value if we got exactly one match in step 3)\"\"\"\n    series_str = df[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n    series_shifted_str = df[cols].shift(lag+2, axis=1)[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n    target_rows = series_shifted_str.progress_apply(lambda x: np.where(x == series_str)[0])\n    target_vals = target_rows.apply(lambda x: df.loc[x[0], cols[lag]] if len(x)==1 else 0)\n    return target_vals\n\ndef get_all_leak(df, cols=None, nlags=15):\n    \"\"\"\n    We just recursively fetch target value for different lags\n    \"\"\"\n    df =  df.copy()\n    #with Pool(processes=CPU_CORES) as p:\n    #    res = [p.apply_async(_get_leak, args=(df, cols, i)) for i in range(nlags)]\n    #    res = [r.get() for r in res]\n    \n    for i in range(nlags):\n        print(\"Processing lag {}\".format(i))\n        df[\"leaked_target_\"+str(i)] = _get_leak(df, cols, i)\n    return df\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1158e5d98cda3d48d8ed8cc07d93b19829e5b412",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test[\"target\"] = train[\"target\"].mean()\n\nall_df = pd.concat([train[[\"ID\", \"target\"] + cols], test[[\"ID\", \"target\"]+ cols]]).reset_index(drop=True)\nall_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c51d07c04c1af45bd4bc1f297f7416ce7dd88548",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "NLAGS = 35 #Increasing this might help push score a bit\nall_df = get_all_leak(all_df, cols=cols, nlags=NLAGS)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a9bc6b9a8a78fd0898668f899ae46245c2126e3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "leaky_cols = [\"leaked_target_\"+str(i) for i in range(NLAGS)]\ntrain = train.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")\ntest = test.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24b1b9fbd1626397503ed142c6eeeef04970edf2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train[[\"target\"]+leaky_cols].head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "23a5c3edd5556ee8e71d9d2659d9abcb9500ad5d"
      },
      "cell_type": "code",
      "source": "train[\"nonzero_mean\"] = train[transact_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)\ntest[\"nonzero_mean\"] = test[transact_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9e85f6d8444bdd2ba144502a998558cb926efb8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#We start with 1st lag target and recusrsively fill zero's\ntrain[\"compiled_leak\"] = 0\ntest[\"compiled_leak\"] = 0\nfor i in range(NLAGS):\n    train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n    test.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n    \nprint(\"Leak values found in train and test \", sum(train[\"compiled_leak\"] > 0), sum(test[\"compiled_leak\"] > 0))\nprint(\"% of correct leaks values in train \", sum(train[\"compiled_leak\"] == train[\"target\"])/sum(train[\"compiled_leak\"] > 0))\n\ntrain.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"nonzero_mean\"]\ntest.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"nonzero_mean\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "49c9d5e53e52c4307aef6ac402868aaee8566700",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(y, np.log1p(train[\"compiled_leak\"]).fillna(14.49)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc2e522df90f97456e67f26977fde364acf02876",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#submission\nsub = test[[\"ID\"]]\nsub[\"target\"] = test[\"compiled_leak\"]\nsub.to_csv(\"baseline_submission_with_leaks.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "df0d5b05147315d10aa81f5f28c4b2173c103d89"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}